
###############################################
Part: 0
Lowest value loss: 14.799296406476925
Epoch with lowest value loss: 1

# Dataset:
Normalize input: True
Normalize output: True
# Architecture:
Hidden layers: 3
Hidden units: [256, 6, 32]
Activation function: relu
Optimizer: adam
Loss function: mean_squared_error

# Hyper parameters:
Max epochs: 1
Batch size: 32
Learning rate: 0.001
Dropout rate: 0.2
Initial weight limit: 0.1
###############################################
Best:
14.799296406476925
###############################################
Part: 0
Lowest value loss: 1.0086857759646881
Epoch with lowest value loss: 4

# Dataset:
Normalize input: True
Normalize output: True
# Architecture:
Hidden layers: 3
Hidden units: [256, 6, 32]
Activation function: relu
Optimizer: adam
Loss function: mean_squared_error

# Hyper parameters:
Max epochs: 1000
Batch size: 32
Learning rate: 0.001
Dropout rate: 0.2
Initial weight limit: 0.1
###############################################
Best:
1.0086857759646881
###############################################
Part: 0
Lowest value loss: 1.0084640090282146
Epoch with lowest value loss: 2

# Dataset:
Normalize input: True
Normalize output: True
# Architecture:
Hidden layers: 3
Hidden units: [256, 6, 32]
Activation function: relu
Optimizer: adam
Loss function: mean_squared_error

# Hyper parameters:
Max epochs: 1000
Batch size: 32
Learning rate: 0.01
Dropout rate: 0.2
Initial weight limit: 0.1
###############################################
Best:
1.0084640090282146